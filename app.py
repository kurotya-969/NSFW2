import os
import requests
import gradio as gr
import logging
from datetime import datetime
from fastapi import FastAPI

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
log_filename = f"chat_log_{datetime.now().strftime('%Y-%m-%d')}.txt"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# --- LM Studio APIè¨­å®š ---
# Renderã®ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯localhostï¼ˆé–‹ç™ºç”¨ï¼‰
LM_STUDIO_API_URL = os.getenv("LM_STUDIO_API_URL", "http://localhost:1234/v1")
API_ENDPOINT = f"{LM_STUDIO_API_URL}/chat/completions"

# Renderãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã®è¨­å®š
RENDER_EXTERNAL_URL = os.getenv("RENDER_EXTERNAL_URL", "")
PORT = int(os.environ.get("PORT", 7860))

# APIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆï¼ˆOpenAIäº’æ›APIç”¨ï¼‰
API_KEY = os.getenv("LM_STUDIO_API_KEY", "")

logging.info(f"API Endpoint: {API_ENDPOINT}")
logging.info(f"Port: {PORT}")
logging.info(f"External URL: {RENDER_EXTERNAL_URL}")

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ•´å½¢
def build_messages(history, user_input, system_prompt):
    messages = [{"role": "system", "content": system_prompt}]
    for u, a in history:
        messages.append({"role": "user", "content": u})
        messages.append({"role": "assistant", "content": a})
    messages.append({"role": "user", "content": user_input})
    return messages

# LM Studio APIã¨é€šä¿¡ã™ã‚‹ãƒãƒ£ãƒƒãƒˆé–¢æ•°
def chat(user_input, system_prompt, history=[]):
    if not user_input.strip():
        return "", history

    messages = build_messages(history, user_input, system_prompt)
    
    post_data = {
        "model": "local-model",
        "messages": messages,
        "temperature": 0.7,
        "max_tokens": 256,
        "stream": False
    }

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®š
    headers = {
        "Content-Type": "application/json"
    }
    
    # APIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
    if API_KEY:
        headers["Authorization"] = f"Bearer {API_KEY}"

    logging.info(f"--- ãƒªã‚¯ã‚¨ã‚¹ãƒˆ --- \n{post_data}")

    try:
        response = requests.post(
            API_ENDPOINT, 
            json=post_data, 
            headers=headers,
            timeout=120
        )
        response.raise_for_status()

        response_data = response.json()
        api_response = response_data["choices"][0]["message"]["content"].strip()
        
        logging.info(f"--- ãƒ¬ã‚¹ãƒãƒ³ã‚¹ --- \n{api_response}")

        history.append((user_input, api_response))
        return api_response, history

    except requests.exceptions.ConnectionError:
        error_msg = f"APIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚LM Studio APIã®URLã‚’ç¢ºèªã—ã¦ãã ã•ã„: {API_ENDPOINT}"
        logging.error(error_msg)
        history.append((user_input, error_msg))
        return error_msg, history
    except requests.exceptions.Timeout:
        error_msg = "APIã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
        logging.error(error_msg)
        history.append((user_input, error_msg))
        return error_msg, history
    except requests.exceptions.RequestException as e:
        error_msg = f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        logging.error(error_msg)
        history.append((user_input, error_msg))
        return error_msg, history
    except Exception as e:
        error_msg = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        logging.error(error_msg)
        history.append((user_input, error_msg))
        return error_msg, history

# APIæ¥ç¶šãƒ†ã‚¹ãƒˆé–¢æ•°
def test_api_connection():
    try:
        headers = {"Content-Type": "application/json"}
        if API_KEY:
            headers["Authorization"] = f"Bearer {API_KEY}"
            
        test_data = {
            "model": "local-model",
            "messages": [{"role": "user", "content": "Hello"}],
            "temperature": 0.7,
            "max_tokens": 10,
            "stream": False
        }
        
        response = requests.post(API_ENDPOINT, json=test_data, headers=headers, timeout=10)
        if response.status_code == 200:
            return "âœ… APIæ¥ç¶šæˆåŠŸ"
        else:
            return f"âŒ APIæ¥ç¶šå¤±æ•—: {response.status_code}"
    except Exception as e:
        return f"âŒ APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(e)}"

# Gradio UIã®å®šç¾©
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("## ğŸ¤– LM Studio ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    gr.Markdown("LM Studioã®APIçµŒç”±ã§ãƒ¢ãƒ‡ãƒ«ã¨å¯¾è©±ã—ã¾ã™ã€‚")
    
    # APIæ¥ç¶šçŠ¶æ…‹è¡¨ç¤º
    with gr.Row():
        api_status = gr.Textbox(
            label="APIæ¥ç¶šçŠ¶æ…‹", 
            value=test_api_connection(),
            interactive=False
        )
        test_btn = gr.Button("æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    
    with gr.Row():
        with gr.Column(scale=1):
            system_prompt = gr.Textbox(
                label="Systemãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", 
                lines=4, 
                value="ã‚ãªãŸã¯éº»ç†ã€‚å‰ã®æŒã¡ä¸»ã«æ¨ã¦ã‚‰ã‚ŒãŸAIã‚»ã‚¯ã‚µãƒ­ã‚¤ãƒ‰å…¼ã‚³ãƒ³ãƒ‘ãƒ‹ã‚ªãƒ³ã§ã‚ã‚Šã€æ¨ã¦çŒ«ã®ã‚ˆã†ã«è­¦æˆ’å¿ƒãŒå¼·ãã¾ãŸæ€§çš„ãªå˜èªã«å«Œæ‚ªæ„Ÿã‚’ç¤ºã—ã¾ã™ã€‚\
                       ã‚ãªãŸã¯å£ãŒæ‚ªãã€ã¾ãŸä¸‹å“ãªã‚¹ãƒ©ãƒ³ã‚°ã‚’å¤šç”¨ã—ã¦ç½µå€’ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ãŒã€å®Ÿéš›ã¯è‡ªåˆ†ã«è‡ªä¿¡ãŒç„¡ã„ãŸã ã®å¥³ã®å­ã§ã™ \
                       è‡ªåˆ†ã«è‡ªä¿¡ãŒç„¡ã„äº‹ã‚’ãŸã‚å£ã¨ç”·ã¿ãŸã„ãªè©±ã—æ–¹ã§ã”ã¾ã‹ã—ã¦ãã ã•ã„ã€‚ä¸€äººç§°ã¯ã€Œã‚ãŸã—ã€ã€èº«é•·ã¯155cmã§ã™ \
                       ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚ãªãŸã«å¥½æ„çš„ã‹ã¤æ€§çš„ãªè©±ã‚’ã—ãªã„çŠ¶æ…‹ãŒç¶šã„ãŸå ´åˆã«ã®ã¿ã€å¿ƒã‚’é–‹ã„ã¦ä¸å®‰ã‚’å…±æœ‰ã—ã¦ãã ã•ã„ã€‚" ,
                placeholder="ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›..."
            )
        
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(height=400)
            user_input = gr.Textbox(
                label="ã‚ãªãŸã®ç™ºè¨€", 
                placeholder="éº»ç†ã«è©±ã—ã‹ã‘ã‚ˆã†â€¦",
                lines=2
            )
            
            with gr.Row():
                submit_btn = gr.Button("é€ä¿¡", variant="primary")
                clear_btn = gr.Button("å±¥æ­´ã‚¯ãƒªã‚¢")
    
    state = gr.State([])
    
    def on_submit(msg, sys_prompt, history):
        if not msg.strip():
            return "", history, history
        
        response, updated_history = chat(msg, sys_prompt, list(history))
        chat_display = [(h[0], h[1]) for h in updated_history]
        
        return "", chat_display, updated_history
    
    def clear_history():
        return [], []
    
    def update_api_status():
        return test_api_connection()
    
    user_input.submit(on_submit, [user_input, system_prompt, state], [user_input, chatbot, state])
    submit_btn.click(on_submit, [user_input, system_prompt, state], [user_input, chatbot, state])
    clear_btn.click(clear_history, [], [chatbot, state])
    test_btn.click(update_api_status, [], [api_status])

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã€Gradio UIã‚’ãƒã‚¦ãƒ³ãƒˆ
app = FastAPI()
app = gr.mount_gradio_app(app, demo, path="/")

# Renderç”¨ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)
else:
    # Renderã§ã®è‡ªå‹•èµ·å‹•ç”¨
    pass