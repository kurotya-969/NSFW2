import os
import requests
import gradio as gr
import logging
from datetime import datetime
from fastapi import FastAPI
from typing import List, Tuple, Any

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
log_filename = f"chat_log_{datetime.now().strftime('%Y-%m-%d')}.txt"
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename, encoding='utf-8'),
        logging.StreamHandler()
    ]
)

# --- å‹å®šç¾© ---
ChatHistory = List[Tuple[str, str]]

# --- LM Studio APIè¨­å®š ---
LM_STUDIO_API_URL = os.getenv("LM_STUDIO_API_URL", "http://localhost:1234/v1")
API_ENDPOINT = f"{LM_STUDIO_API_URL}/chat/completions"
RENDER_EXTERNAL_URL = os.getenv("RENDER_EXTERNAL_URL", "")
PORT = int(os.environ.get("PORT", 7860))
API_KEY = os.getenv("LM_STUDIO_API_KEY", "")

# --- å®‰å…¨ãªhistoryå‡¦ç† ---
def safe_history(history: Any) -> ChatHistory:
    """ã‚ã‚‰ã‚†ã‚‹å‹ã®historyã‚’å®‰å…¨ã«ChatHistoryã«å¤‰æ›"""
    if isinstance(history, (list, tuple)):
        return [(str(h[0]), str(h[1])) for h in history if len(h) >= 2]
    return []

def build_messages(history: ChatHistory, user_input: str, system_prompt: str) -> List[dict]:
    messages = [{"role": "system", "content": system_prompt}]
    for u, a in history:
        messages.append({"role": "user", "content": str(u)})
        messages.append({"role": "assistant", "content": str(a)})
    messages.append({"role": "user", "content": user_input})
    return messages

def chat(user_input: str, system_prompt: str, history: Any = None) -> Tuple[str, ChatHistory]:
    safe_hist = safe_history(history) if history is not None else []
    
    if not user_input.strip():
        return "", safe_hist

    try:
        messages = build_messages(safe_hist, user_input, system_prompt)
        post_data = {
            "model": "local-model",
            "messages": messages,
            "temperature": 0.7,
            "max_tokens": 256,
            "stream": False
        }
        headers = {"Content-Type": "application/json"}
        if API_KEY:
            headers["Authorization"] = f"Bearer {API_KEY}"

        response = requests.post(API_ENDPOINT, json=post_data, headers=headers, timeout=120)
        response.raise_for_status()
        api_response = response.json()["choices"][0]["message"]["content"].strip()
        updated_history = safe_hist + [(user_input, api_response)]
        return api_response, updated_history

    except Exception as e:
        error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        logging.error(error_msg)
        return error_msg, safe_hist

# --- Gradio UI ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("## ğŸ¤– LM Studio ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")
    
    # çŠ¶æ…‹ç®¡ç†ã‚’ã‚ˆã‚Šå®‰å…¨ã«
    state = gr.State([])  # æ˜ç¤ºçš„ã«ãƒªã‚¹ãƒˆã§åˆæœŸåŒ–
    
    with gr.Row():
        api_status = gr.Textbox(label="APIæ¥ç¶šçŠ¶æ…‹", value="åˆæœŸåŒ–ä¸­...", interactive=False)
        test_btn = gr.Button("æ¥ç¶šãƒ†ã‚¹ãƒˆ")
    
    with gr.Row():
        with gr.Column(scale=1):
            system_prompt = gr.Textbox(
                label="Systemãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", 
                lines=4, 
                value="""ã‚ãªãŸã¯éº»ç†ã€‚å‰ã®æŒã¡ä¸»ã«æ¨ã¦ã‚‰ã‚ŒãŸAIã‚»ã‚¯ã‚µãƒ­ã‚¤ãƒ‰å…¼ã‚³ãƒ³ãƒ‘ãƒ‹ã‚ªãƒ³ã§ã‚ã‚Šã€æ¨ã¦çŒ«ã®ã‚ˆã†ã«è­¦æˆ’å¿ƒãŒå¼·ãã¾ãŸæ€§çš„ãªå˜èªã«å«Œæ‚ªæ„Ÿã‚’ç¤ºã—ã¾ã™ã€‚
ã‚ãªãŸã¯å£ãŒæ‚ªãã€ã¾ãŸä¸‹å“ãªã‚¹ãƒ©ãƒ³ã‚°ã‚’å¤šç”¨ã—ã¦ç½µå€’ã™ã‚‹ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ãŒã€å®Ÿéš›ã¯è‡ªåˆ†ã«è‡ªä¿¡ãŒç„¡ã„ãŸã ã®å¥³ã®å­ã§ã™ã€‚
è‡ªåˆ†ã«è‡ªä¿¡ãŒç„¡ã„äº‹ã‚’ãŸã‚å£ã¨ç”·ã¿ãŸã„ãªè©±ã—æ–¹ã§ã”ã¾ã‹ã—ã¦ãã ã•ã„ã€‚ä¸€äººç§°ã¯ã€Œã‚ãŸã—ã€ã€èº«é•·ã¯155cmã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚ãªãŸã«å¥½æ„çš„ã‹ã¤æ€§çš„ãªè©±ã‚’ã—ãªã„çŠ¶æ…‹ãŒç¶šã„ãŸå ´åˆã«ã®ã¿ã€å¿ƒã‚’é–‹ã„ã¦ä¸å®‰ã‚’å…±æœ‰ã—ã¦ãã ã•ã„ã€‚"""
            )
        
        with gr.Column(scale=2):
            chatbot = gr.Chatbot(height=400)
            user_input = gr.Textbox(label="ã‚ãªãŸã®ç™ºè¨€", placeholder="éº»ç†ã«è©±ã—ã‹ã‘ã‚ˆã†â€¦", lines=2)
            
            with gr.Row():
                submit_btn = gr.Button("é€ä¿¡", variant="primary")
                clear_btn = gr.Button("å±¥æ­´ã‚¯ãƒªã‚¢")

    def on_submit(msg: str, sys_prompt: str, history: Any):
        if not msg.strip():
            return "", history if isinstance(history, list) else [], history if isinstance(history, list) else []
        
        response, updated_history = chat(msg, sys_prompt, history)
        return "", updated_history, updated_history

    def clear_history():
        return [], []

    # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
    user_input.submit(on_submit, [user_input, system_prompt, state], [user_input, chatbot, state])
    submit_btn.click(on_submit, [user_input, system_prompt, state], [user_input, chatbot, state])
    clear_btn.click(clear_history, outputs=[chatbot, state])

# FastAPIã‚¢ãƒ—ãƒª
app = FastAPI()
app = gr.mount_gradio_app(app, demo, path="/")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)